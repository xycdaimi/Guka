ImportError: cannot import name 'DialogueDataset' from 'data' (unknown location)
2024-02-06 18:26:57,337 | Guka_Server.comunication.comunication | comunication.py[line:16] |  ERROR: [Errno 13] Permission denied |  __init__
2024-02-06 18:26:57,338 | Guka_Server.comunication.comunication | comunication.py[line:24] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 18:26:57,492 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: Failed to load audio: ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers
  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)
  configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame
  libavutil      56. 51.100 / 56. 51.100
  libavcodec     58. 91.100 / 58. 91.100
  libavformat    58. 45.100 / 58. 45.100
  libavdevice    58. 10.100 / 58. 10.100
  libavfilter     7. 85.100 /  7. 85.100
  libavresample   4.  0.  0 /  4.  0.  0
  libswscale      5.  7.100 /  5.  7.100
  libswresample   3.  7.100 /  3.  7.100
: No such file or directory
 |  forward
2024-02-06 18:26:57,492 | Guka_Server.comunication.comunication | comunication.py[line:24] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 18:26:57,600 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: Failed to load audio: ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers
  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)
 |  is_listen
2024-02-06 18:33:48,275 | Guka_Server.comunication.comunication | comunication.py[line:24] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 18:46:40,858 | Guka_Server.comunication.comunication | comunication.py[line:18] |  ERROR: [Errno 13] Permission denied |  __init__
2024-02-06 18:46:40,859 | Guka_Server.comunication.comunication | comunication.py[line:24] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 18:46:40,866 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got NoneType) |  forward
2024-02-06 18:51:05,060 | Guka_Server.comunication.comunication | comunication.py[line:16] |  ERROR: [Errno 13] Permission denied |  __init__
2024-02-06 18:51:05,060 | Guka_Server.comunication.comunication | comunication.py[line:22] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 18:51:05,061 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got NoneType) |  forward
2024-02-06 19:02:45,198 | Guka_Server.comunication.comunication | comunication.py[line:16] |  ERROR: bind(): port must be 0-65535. |  __init__
2024-02-06 19:02:45,199 | Guka_Server.comunication.comunication | comunication.py[line:22] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 19:02:45,199 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got NoneType) |  forward
2024-02-06 19:03:42,813 | Guka_Server.comunication.comunication | comunication.py[line:16] |  ERROR: [Errno 13] Permission denied |  __init__
2024-02-06 19:03:42,813 | Guka_Server.comunication.comunication | comunication.py[line:22] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 19:03:42,814 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got NoneType) |  forward
2024-02-06 20:44:45,222 | Guka_Server.comunication.comunication | comunication.py[line:16] |  ERROR: [Errno 13] Permission denied |  __init__
2024-02-06 20:44:45,222 | Guka_Server.comunication.comunication | comunication.py[line:22] |  ERROR: 'Com' object has no attribute 'conn' |  is_listen
2024-02-06 21:48:37,758 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,759 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,766 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,778 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,778 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,779 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,808 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,809 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,816 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,828 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 21:48:37,828 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 22:37:09,016 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 22:37:09,016 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 22:37:09,016 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: expected np.ndarray (got bytes) |  forward
2024-02-06 23:07:34,153 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-06 23:07:34,158 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-06 23:07:34,163 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-06 23:07:34,167 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-06 23:07:34,176 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-06 23:07:34,180 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-06 23:07:34,223 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: stft(torch.ShortTensor[480912], n_fft=400, hop_length=160, win_length=400, window=torch.FloatTensor{[400]}, normalized=0, onesided=None, return_complex=1) : expected a tensor of floating point or complex values |  forward
2024-02-08 18:10:34,933 | Guka_Server | main.py[line:39] |  ERROR: sequence item 0: expected a bytes-like object, int found |  <module>
2024-02-08 18:10:34,933 | Guka_Server | main.py[line:39] |  ERROR: sequence item 0: expected a bytes-like object, int found |  <module>
Exception ignored in: <function Wave_write.__del__ at 0x7f7eb385e9d0>
Traceback (most recent call last):
  File "/home/daimi/miniconda3/envs/guka/lib/python3.9/wave.py", line 326, in __del__
  File "/home/daimi/miniconda3/envs/guka/lib/python3.9/wave.py", line 444, in close
  File "/home/daimi/miniconda3/envs/guka/lib/python3.9/wave.py", line 467, in _ensure_header_written
  File "/home/daimi/miniconda3/envs/guka/lib/python3.9/wave.py", line 479, in _write_header
AttributeError: 'NoneType' object has no attribute 'pack'
Traceback (most recent call last):
  File "D:\作业项目\智能应用\Guka\code\client\main.py", line 26, in <module>
    dt = b''.join(data)
TypeError: sequence item 0: expected a bytes-like object, int found
Traceback (most recent call last):
  File "D:\作业项目\智能应用\Guka\code\client\main.py", line 36, in <module>
    stream.write(data)
  File "D:\作业项目\智能应用\Guka\code\venv\lib\site-packages\pyaudio\__init__.py", line 542, in write
    raise IOError("Not output stream",
OSError: [Errno Not output stream] -9974
2024-02-09 13:41:35,875 | Guka_Server.comunication.comunication | comunication.py[line:34] |  ERROR: [Errno -9996] Invalid output device (no default output device) |  __init__
2024-02-09 13:41:40,390 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: Failed to load audio: ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers
  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)
  configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame
  libavutil      56. 51.100 / 56. 51.100
  libavcodec     58. 91.100 / 58. 91.100
  libavformat    58. 45.100 / 58. 45.100
  libavdevice    58. 10.100 / 58. 10.100
  libavfilter     7. 85.100 /  7. 85.100
  libavresample   4.  0.  0 /  4.  0.  0
  libswscale      5.  7.100 /  5.  7.100
  libswresample   3.  7.100 /  3.  7.100
recording.wav: Invalid data found when processing input
 |  forward
2024-02-09 13:41:40,391 | Guka_Server | main.py[line:34] |  ERROR: a bytes-like object is required, not 'NoneType' |  <module>
2024-02-09 13:46:37,045 | Guka_Server.comunication.comunication | comunication.py[line:34] |  ERROR: [Errno -9996] Invalid output device (no default output device) |  __init__
2024-02-09 13:50:18,326 | Guka_Server.comunication.comunication | comunication.py[line:34] |  ERROR: [Errno -9996] Invalid output device (no default output device) |  __init__
2024-02-09 13:50:30,535 | Guka_Server.comunication.comunication | comunication.py[line:63] |  ERROR: 'Com' object has no attribute 'stream' |  close_down
2024-02-09 14:38:00,074 | Guka_Server.speak.speak | speak.py[line:16] |  ERROR: Unsupported language: zh-cn |  forward
2024-02-09 14:47:27,319 | Guka_Server.speak.speak | speak.py[line:18] |  ERROR: __init__() got an unexpected keyword argument 'device' |  forward
2024-02-09 15:13:56,434 | Guka_Server.comunication.comunication | comunication.py[line:28] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-09 15:13:56,435 | Guka_Server | main.py[line:36] |  ERROR: 'Com' object has no attribute 'p' |  <module>
2024-02-09 15:41:54,705 | Guka_Server | main.py[line:38] |  ERROR: [Errno 104] Connection reset by peer |  <module>
2024-02-09 15:44:39,321 | Guka_Server.comunication.comunication | comunication.py[line:28] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-09 15:44:39,321 | Guka_Server | main.py[line:37] |  ERROR: 'Com' object has no attribute 'p' |  <module>
2024-02-09 15:45:14,808 | Guka_Server.comunication.comunication | comunication.py[line:28] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-09 15:45:14,808 | Guka_Server | main.py[line:37] |  ERROR: 'Com' object has no attribute 'p' |  <module>
2024-02-09 16:16:37,490 | Guka_Server | main.py[line:38] |  ERROR: 'utf-8' codec can't decode byte 0xff in position 4: invalid start byte |  <module>
2024-02-09 16:27:48,362 | Guka_Server | main.py[line:38] |  ERROR: 'utf-8' codec can't decode byte 0xff in position 4: invalid start byte |  <module>
2024-02-10 16:47:25,108 | Guka_Server.comunication.comunication | comunication.py[line:28] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-10 16:47:25,109 | Guka_Server | main.py[line:38] |  ERROR: 'Com' object has no attribute 'p' |  <module>
2024-02-10 17:06:46,432 | Guka_Server.chatglm.chatglm | chatglm.py[line:16] |  INFO: 使用GPU |  __init__
2024-02-10 17:06:46,434 | Guka_Server.chatglm.chatglm | chatglm.py[line:29] |  INFO: 历史对话加载完成 |  __init__
2024-02-10 17:06:46,435 | Guka_Server.chatglm.chatglm | chatglm.py[line:33] |  INFO: 对话模型初始化完成 |  __init__
2024-02-10 17:06:55,984 | Guka_Server.speak.speak | speak.py[line:9] |  INFO: 语音识别模型初始化完成 |  __init__
2024-02-10 17:06:56,396 | Guka_Server.comunication.comunication | comunication.py[line:26] |  INFO: 语音监听开启 |  __init__
2024-02-10 17:07:12,357 | Guka_Server | main.py[line:32] |  INFO: 下午好啊,姑咖 |  <module>
2024-02-10 17:07:14,639 | Guka_Server | main.py[line:35] |  INFO: 下午好，姑咖！有什么需要帮忙的吗？ |  <module>
2024-02-10 17:07:14,640 | Guka_Server.comunication.comunication | comunication.py[line:53] |  INFO: 连接关闭 |  close_down
2024-02-10 17:07:14,640 | Guka_Server | main.py[line:38] |  INFO: 回答发送完毕 |  <module>
2024-02-10 17:23:40,248 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:00,425 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:00,543 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:00,662 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:00,779 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:00,899 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,016 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,135 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,252 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,370 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,488 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,607 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,724 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,846 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:01,964 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,082 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,200 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,318 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,436 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,558 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,686 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,805 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:02,924 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:03,042 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:03,160 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-10 17:32:03,277 | Guka_Server | main.py[line:26] |  ERROR: local variable 'res' referenced before assignment |  start_main
2024-02-15 13:07:58,897 | Guka_Server.comunication.comunication | comunication.py[line:29] |  ERROR: cannot unpack non-iterable NoneType object |  __init__
2024-02-15 13:08:07,690 | Guka_Server | main.py[line:47] |  ERROR: can only concatenate str (not "int") to str |  start_main
2024-02-15 13:09:25,475 | Guka_Server.comunication.comunication | comunication.py[line:29] |  ERROR: cannot unpack non-iterable NoneType object |  __init__
2024-02-15 13:09:43,598 | Guka_Server | main.py[line:49] |  ERROR: can only concatenate str (not "int") to str |  start_main
2024-02-15 13:15:53,448 | Guka_Server | main.py[line:79] |  ERROR: 'Com' object has no attribute 'conn' |  <module>
2024-02-15 13:16:58,387 | Guka_Server.comunication.comunication | comunication.py[line:29] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-15 13:16:58,387 | Guka_Server | main.py[line:79] |  ERROR: [Errno 22] Invalid argument |  <module>
2024-02-15 13:23:16,937 | Guka_Server | main.py[line:79] |  ERROR: 'Com' object has no attribute 'conn' |  <module>
2024-02-15 13:24:38,171 | Guka_Server | main.py[line:49] |  ERROR: can only concatenate str (not "int") to str |  start_main
2024-02-15 14:04:15,201 | Guka_Server | main.py[line:49] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-15 14:10:33,383 | Guka_Server.speak.speak | speak.py[line:18] |  ERROR: Failed to load audio: ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers
  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)
  configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame
  libavutil      56. 51.100 / 56. 51.100
  libavcodec     58. 91.100 / 58. 91.100
  libavformat    58. 45.100 / 58. 45.100
  libavdevice    58. 10.100 / 58. 10.100
  libavfilter     7. 85.100 /  7. 85.100
  libavresample   4.  0.  0 /  4.  0.  0
  libswscale      5.  7.100 /  5.  7.100
  libswresample   3.  7.100 /  3.  7.100
recording.wav: No such file or directory
 |  forward
2024-02-15 14:12:28,070 | Guka_Server | main.py[line:49] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-15 14:19:43,767 | Guka_Server | main.py[line:49] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-15 14:32:31,838 | Guka_Server | main.py[line:51] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-15 16:19:04,602 | Guka_Server | main.py[line:56] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-15 17:31:40,924 | Guka_Server.chatglm.chatglm | chatglm.py[line:35] |  ERROR: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 11.76 GiB of which 7.69 MiB is free. Process 6891 has 8.69 GiB memory in use. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.75 GiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) |  __init__
2024-02-15 17:31:53,064 | Guka_Server.speak.speak | speak.py[line:11] |  ERROR: Error(s) in loading state_dict for Whisper:
	While copying the parameter named "encoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',). |  __init__
2024-02-15 17:31:53,110 | Guka_Server.comunication.comunication | comunication.py[line:31] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-15 17:31:53,110 | Guka_Server | main.py[line:86] |  ERROR: [Errno 22] Invalid argument |  <module>
2024-02-15 17:32:45,288 | Guka_Server.chatglm.chatglm | chatglm.py[line:35] |  ERROR: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 11.76 GiB of which 7.69 MiB is free. Process 6891 has 8.69 GiB memory in use. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.75 GiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) |  __init__
2024-02-15 17:32:57,906 | Guka_Server.speak.speak | speak.py[line:11] |  ERROR: Error(s) in loading state_dict for Whisper:
	While copying the parameter named "encoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',). |  __init__
2024-02-15 17:32:57,961 | Guka_Server.comunication.comunication | comunication.py[line:31] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-15 17:32:57,961 | Guka_Server | main.py[line:86] |  ERROR: [Errno 22] Invalid argument |  <module>
2024-02-15 17:35:03,008 | Guka_Server.chatglm.chatglm | chatglm.py[line:35] |  ERROR: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 11.76 GiB of which 7.88 MiB is free. Process 6891 has 8.69 GiB memory in use. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.75 GiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) |  __init__
2024-02-15 17:35:15,162 | Guka_Server.speak.speak | speak.py[line:11] |  ERROR: Error(s) in loading state_dict for Whisper:
	While copying the parameter named "encoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',). |  __init__
2024-02-15 17:35:15,202 | Guka_Server.comunication.comunication | comunication.py[line:31] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-15 17:35:15,202 | Guka_Server | main.py[line:86] |  ERROR: [Errno 22] Invalid argument |  <module>
2024-02-15 17:35:37,705 | Guka_Server.chatglm.chatglm | chatglm.py[line:35] |  ERROR: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 11.76 GiB of which 7.88 MiB is free. Process 6891 has 8.69 GiB memory in use. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.75 GiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) |  __init__
2024-02-15 17:35:49,999 | Guka_Server.speak.speak | speak.py[line:11] |  ERROR: Error(s) in loading state_dict for Whisper:
	While copying the parameter named "encoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "encoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.0.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.1.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.2.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.3.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.4.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.5.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.6.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.7.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.8.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.9.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.10.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.11.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.12.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.13.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.14.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.15.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.16.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.17.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.18.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.19.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.20.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.21.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.22.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.query.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.key.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.value.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.cross_attn.out.weight", whose dimensions in the model are torch.Size([1024, 1024]) and whose dimensions in the checkpoint are torch.Size([1024, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.0.weight", whose dimensions in the model are torch.Size([4096, 1024]) and whose dimensions in the checkpoint are torch.Size([4096, 1024]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',).
	While copying the parameter named "decoder.blocks.23.mlp.2.weight", whose dimensions in the model are torch.Size([1024, 4096]) and whose dimensions in the checkpoint are torch.Size([1024, 4096]), an exception occurred : ('CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n',). |  __init__
2024-02-15 17:35:50,013 | Guka_Server.comunication.comunication | comunication.py[line:31] |  ERROR: [Errno 98] Address already in use |  __init__
2024-02-15 17:35:50,013 | Guka_Server | main.py[line:86] |  ERROR: [Errno 22] Invalid argument |  <module>
2024-02-21 01:47:35,033 | Guka_Server | main.py[line:52] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-21 01:50:40,819 | Guka_Server | main.py[line:52] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-21 01:53:08,246 | Guka_Server | main.py[line:52] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-21 02:01:57,291 | Guka_Server | main.py[line:52] |  ERROR: [Errno 104] Connection reset by peer |  start_main
2024-02-21 09:28:29,622 | Guka_Server.speak.speak | speak.py[line:18] |  ERROR: Failed to load audio: ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers
  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)
  configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame
  libavutil      56. 51.100 / 56. 51.100
  libavcodec     58. 91.100 / 58. 91.100
  libavformat    58. 45.100 / 58. 45.100
  libavdevice    58. 10.100 / 58. 10.100
  libavfilter     7. 85.100 /  7. 85.100
  libavresample   4.  0.  0 /  4.  0.  0
  libswscale      5.  7.100 /  5.  7.100
  libswresample   3.  7.100 /  3.  7.100
recoding1.wav: No such file or directory
 |  forward
2024-02-21 09:28:29,623 | Guka_Server | main.py[line:52] |  ERROR: 'NoneType' object has no attribute 'encode' |  start_main
2024-02-21 09:29:42,463 | Guka_Server | main.py[line:52] |  ERROR: [Errno 104] Connection reset by peer |  start_main
